{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary packages\n",
    "import benepar, spacy\n",
    "# treeswift package https://niemasd.github.io/TreeSwift/\n",
    "import treeswift\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up spacy parser\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example\n",
    "doc = nlp(\"So that should be like exactly the same thing\")\n",
    "\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File imports\n",
    "df_ms = 'your dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a turn starts with a \" \", remove it. There's some issues with the Dec2019 data\n",
    "df_ms = df_ms.replace(to_replace =\"^\\s+\", value = '', regex = True)\n",
    "# remove the double parenthesis, and quotation marks in some conversations\n",
    "df_ms = df_ms.replace(to_replace =\"\\(\\(\", value = '', regex = True)\n",
    "df_ms = df_ms.replace(to_replace =\"\\)\\)\", value = '', regex = True)\n",
    "df_ms = df_ms.replace(to_replace ='\\\"', value = '', regex = True)\n",
    "\n",
    "df_ms['Text'].replace('', np.nan, inplace=True)\n",
    "df_ms = df_ms[df_ms['Text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 3rd party speaker's utterance\n",
    "df_ms = df_ms[df_ms.other_speech != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within each group, merge multiple rows of the same speaker's uttences to one\n",
    "df_ms['key'] = ((df_ms['group']!= df_ms['group'].shift(1))|\n",
    "                (df_ms['Speaker']!= df_ms['Speaker'].shift(1))).astype(int).cumsum()\n",
    "df_show = df_ms.groupby(['key','group','Speaker'])['Text'].apply(' '.join)\n",
    "df_ms = df_show.to_frame().reset_index()\n",
    "# print(type(df_show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the turn id within groups \n",
    "df_ms['group_turn_id'] = df_ms.groupby(['group']).cumcount()+1\n",
    "# add the speaker turn id within groups \n",
    "df_ms['group_speaker_turn_id'] = df_ms.groupby(['group','Speaker']).cumcount()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get syntax tree for each utterance, calculate SILLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the NaN values in 'Text' column to [] so it can be treated universally\n",
    "df_ms['Text'] = [ '' if x is np.NaN else x for x in df_ms['Text'] ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 for each full syntax tree of a sentence, get the list of subtrees (as target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree(full_syntax_tree):\n",
    "    # handle a few special cases that fail to parse as newick tree. \n",
    "    newick_tree = full_syntax_tree.replace(\"'\", \"\").replace(\" \", \",\").replace(\";\", \"\").replace(\":\", \"\").replace('\"',\"\")\n",
    "    tree_read = treeswift.read_tree_newick(newick_tree)\n",
    "    tree_list = []\n",
    "    previous_subtree = []\n",
    "    two_level_subtree = []\n",
    "    for node in tree_read.traverse_levelorder(leaves=True, internal=True):\n",
    "        subtree = tree_read.extract_subtree(node)\n",
    "        subtree_list = list(subtree.labels())\n",
    "        # find when to create the new list and append\n",
    "        # the item in the previous_subtree is the parent, and the last item in the subtree_list is the child\n",
    "        if len(subtree_list) > 1 and len(previous_subtree) == 1 :\n",
    "            two_level_subtree = []\n",
    "            two_level_subtree.append(previous_subtree[0])\n",
    "            two_level_subtree.append(subtree_list[len(subtree_list)-1])\n",
    "        # still the same tree, add another child item to the list\n",
    "        elif len(subtree_list) > 1 and len(previous_subtree) > 1: \n",
    "            two_level_subtree.append(subtree_list[len(subtree_list)-1])\n",
    "        # move to a different tree, finish appending the two_level_subtree and append it to the tree_list\n",
    "        elif len(subtree_list) == 1 and len(previous_subtree) > 1:\n",
    "            if two_level_subtree != []: # exclude the special first '[]' case\n",
    "                tree_list.append(two_level_subtree)        \n",
    "        previous_subtree = subtree_list\n",
    "        for tree in tree_list: # remove non-meaningful tags\n",
    "            tree = remove_bad_tags(tree)\n",
    "    # print(\"tree list:\", tree_list) \n",
    "    return tree_list\n",
    "    \n",
    "def remove_bad_tags(tree): # tree looks like: ['INTJ', 'UH', '.']\n",
    "    for items in tree: \n",
    "        if items == '': tree.remove('')\n",
    "        if items == '.': tree.remove('.')\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subtrees for all utterances in a conversation, output a dictionary, key is the index of df_ms\n",
    "# this takes ~15 mins to run (for middle school data)\n",
    "def get_subtree_dict(df_ms):\n",
    "    subtree_dict = {} # a dictionary, key = utterance index, value = subtree list \n",
    "    n = 0\n",
    "    for index, row in df_ms.iterrows(): # i is the index of df_ms\n",
    "        text =  df_ms.at[index,'Text'] # text is an utterance\n",
    "        # print(text)\n",
    "        sent = list(nlp(text).sents)\n",
    "        utterance_subtree_list = [] # initiate the subtree list for an utterance\n",
    "        for j in sent: # j is a sentence in the utterance\n",
    "            syntax_tree = j._.parse_string\n",
    "            # print(syntax_tree)\n",
    "            subtree_list = get_subtree(syntax_tree)\n",
    "            utterance_subtree_list.extend(subtree_list)\n",
    "        subtree_dict[n] = utterance_subtree_list \n",
    "        n = n+1\n",
    "    # if n%10==0: print('hundred')\n",
    "    return subtree_dict\n",
    "\n",
    "# subtree_dict = get_subtree_dict(df_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will take ~15 minutes. you can skip this step if you already have the syntax tree generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the subtree list dict to the dataframe as a column (by [dict key] and [df index])\n",
    "df_ms['syntax_tree_current'] = df_ms.index.map(get_subtree_dict(df_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Get the prime syntax subtree (window size customizable, now is 5 and 10 turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set syntax_tree_prime to be n turns prior to the target turn \n",
    "def get_prime_subtree(df_ms, n): # specify the number of turns  as n, return a dict\n",
    "    prime_dict = {}\n",
    "    # df_ms['syntax_tree_current'].shift(1)\n",
    "    for group,turn_id in zip(df_ms.group, df_ms.group_turn_id):\n",
    "        if turn_id == 1: # when it moves to a new group, store the group_name\n",
    "            group_name = group\n",
    "        #  get the index of the row \n",
    "        index1 = df_ms[(df_ms['group'] == group_name) & (df_ms['group_turn_id'] == turn_id)].index.item()\n",
    "        \n",
    "        if group == group_name: # prime has to be done within the same group\n",
    "            # if index < n, then do everything from 1 to index\n",
    "            prime_count = turn_id//2 # the number of rows priming: turn_id//2. 5//2 = 2\n",
    "            speaker = df_ms.iloc[index1]['Speaker'] # find the value in column 'Speaker' and row 'index1'\n",
    "            \n",
    "            # df_ms[(df_ms['group'] == group_name) & (df_ms['group_turn_id'] == turn_id)].iloc[]\n",
    "            syntax_list = []\n",
    "            if prime_count < n: \n",
    "                # syntax_list: [[['S', 'NP', 'VP', '.']], [['INTJ', 'UH', '.']]]\n",
    "                syntax_list = df_ms[(df_ms['group'] == group_name) & \n",
    "                                    (df_ms['Speaker'] != speaker)].iloc[0: prime_count]['syntax_tree_current'].tolist()\n",
    "            else: \n",
    "                syntax_list = df_ms[(df_ms['group'] == group_name) & \n",
    "                                    (df_ms['Speaker'] != speaker)].iloc[prime_count-n: prime_count]['syntax_tree_current'].tolist()\n",
    "#             print ('corpus index: ', index1, 'speaker: ', speaker, \n",
    "#                    'syntax_list len: ', len(syntax_list))   \n",
    "\n",
    "            # turn to this format: [['S', 'NP', 'VP', '.'], ['INTJ', 'UH', '.']]\n",
    "            syntax_list_reformat = []\n",
    "            for l in syntax_list: # l is the list of syntax rules for a turn, e.g., [['INTJ', 'UH']]\n",
    "                    # print(\"l: \", l)\n",
    "                syntax_list_reformat.extend(l) # add it to the reformatted list      \n",
    "\n",
    "            prime_dict[index1] = syntax_list_reformat # syntax list for prime                 \n",
    "    # print(list(prime_dict.items())[:2])\n",
    "    return prime_dict\n",
    "\n",
    "\n",
    "# list.remove('rabbit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the prime subtree column (10-turn window)\n",
    "df_ms['syntax_tree_prime_10'] = df_ms.index.map(get_prime_subtree(df_ms, 10)) \n",
    "# replace the first row prime NaN to [] so it can be treated universally\n",
    "df_ms['syntax_tree_prime_10'] = [ [] if x is np.NaN else x for x in df_ms['syntax_tree_prime_10'] ] \n",
    "# df_ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the prime subtree column (5-turn window)\n",
    "df_ms['syntax_tree_prime_5'] = df_ms.index.map(get_prime_subtree(df_ms, 5)) \n",
    "# replace the first row prime NaN to [] so it can be treated universally\n",
    "df_ms['syntax_tree_prime_5'] = [ [] if x is np.NaN else x for x in df_ms['syntax_tree_prime_5'] ] \n",
    "df_ms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Calculate the SILLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the overlap items in two lists (target and prime)\n",
    "# calculate the length of utterances\n",
    "def find_overlap(df_ms, prime_window):\n",
    "\n",
    "    prime_column = 'syntax_tree_prime_'+ str(prime_window) # get the column name based on the prime_window chosed \n",
    "    len_prime_column = 'len_prime_' + str(prime_window)\n",
    "    \n",
    "    print(prime_column)\n",
    "    df_ms['overlap_count'] = 0\n",
    "    df_ms['len_target'] = 0\n",
    "    df_ms['len_prime'] = 0\n",
    "\n",
    "    for index, row in df_ms.iterrows():\n",
    "        n=0\n",
    "        list1 = row[prime_column]\n",
    "        list2 = row['syntax_tree_current']\n",
    "        # print(type(list1), type(list2))\n",
    "        for i in list1:\n",
    "            # print(i)\n",
    "            if i in list2: # if the item in list1 belongs to list 2, then n++\n",
    "                n+=1\n",
    "        # add columns (column manipulation: set use df.at, get use df.loc)\n",
    "        \n",
    "        df_ms.at[index,'overlap_count'] = n # set number of items that overlapped between prime and target\n",
    "        df_ms.at[index,'len_target'] = len(list2) # set length of target utterance\n",
    "        df_ms.at[index,'len_prime'] = len(list1) # set length of prime utterance\n",
    "    \n",
    "    return len_prime_column # keep the len_prime column name for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your prime window, currently is 10 \n",
    "find_overlap(df_ms, 10)\n",
    "# df_ms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SILLA = p(target|prime)/p(target) = number of elements overlapped / (len_target*len_prime)\n",
    "df_ms['len_prime_target'] = df_ms['len_target'] * df_ms['len_prime']\n",
    "df_ms['lla'] = df_ms['overlap_count']/df_ms['len_prime_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Normalized LLA (nLLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 compute $\\bar {LLA}$\n",
    "i.e., The average LLA for all pairs that have the same product of length, and for all possible product values n.\n",
    "Outcome of D1 should be a dictionary which the key to be product values (n), value to be the average LLA of all pairs which have that product values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reitter paper idea: normalize by the average LLA for the same product of length, which is len(Prime)*len(target)\n",
    "# \"product of length\" column: len_prime_target\n",
    "grouped_element_length = df_ms.groupby('len_prime_target') # group the df by utternace length \n",
    "print(len(grouped_element_length)) # total of 1657 unique len(Prime)*len(target)\n",
    "\n",
    "avg_lla_list = {} # key = length, value = average_lla, use this to add the column to df later\n",
    "for l in grouped_element_length: # l is a tuple object, l[0] is the element length, l[1] is the subset dataframe\n",
    "    avg_lla = l[1][\"lla\"].mean()\n",
    "    avg_lla_list[l[0]] = avg_lla\n",
    "#     for index, row in l[1].iterrows():\n",
    "#         list(grouped_element_length)[l[0]][1].at[index,'avg_lla'] = avg_lla\n",
    "        # print('yes')\n",
    "print(list(avg_lla_list.items())[:5])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add avg_lla dictionary to the df as a column, mapping by len(Prime)*len(target)\n",
    "df_ms['avg_lla'] = df_ms.len_prime_target.map(avg_lla_list)\n",
    "df_ms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 compute nLLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nLLA = LLA / avg_lla\n",
    "df_ms['nlla'] = df_ms['lla']/df_ms['avg_lla'] \n",
    "df_ms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 (one time run, can be skipped) Post hoc experiment - add a baseline lla for each turn\n",
    "### shuffle the corpus, pick any n turns prior to the *target* turn as *prime*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle = df_ms.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffle[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [7,8,9,10,11,12,13,14,15]\n",
    "df_shuffle.drop(df_shuffle.columns[cols],axis=1,inplace=True)\n",
    "df_shuffle[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set syntax_tree_prime to be n turns prior to the target turn \n",
    "def get_baseline_prime_subtree(df_ms, n): # specify the number of turns  as n, return a dict\n",
    "    prime_dict = {}\n",
    "    # df_ms['syntax_tree_current'].shift(1)\n",
    "    for index in df_ms.index:\n",
    "        # if index < n, then do everything from 1 to index\n",
    "        # print(type(df_ms.iloc[index]['syntax_tree_current']))\n",
    "        syntax_list = []\n",
    "        if index < n: \n",
    "            # syntax_list: [[['S', 'NP', 'VP', '.']], [['INTJ', 'UH', '.']]]\n",
    "            syntax_list = df_ms.iloc[0: index]['syntax_tree_current'].tolist()\n",
    "            # print(syntax_list)\n",
    "        else: \n",
    "            syntax_list = df_ms.iloc[index-n: index]['syntax_tree_current'].tolist()\n",
    "        # turn to this format: [['S', 'NP', 'VP', '.'], ['INTJ', 'UH', '.']]\n",
    "        syntax_list_reformat = []\n",
    "        for l in syntax_list: # l is the list of syntax rules for a turn, e.g., [['INTJ', 'UH']]\n",
    "            syntax_list_reformat.extend(l) # add it to the reformatted list     \n",
    "\n",
    "        prime_dict[index] = syntax_list_reformat # syntax list for prime                 \n",
    "    # print(list(prime_dict.items())[:2])\n",
    "    return prime_dict\n",
    "\n",
    "\n",
    "# list.remove('rabbit')\n",
    "# get_baseline_prime_subtree(df_shuffle[:30], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the random prime from the shuffled df\n",
    "df_shuffle['prime_10_random'] = df_ms.index.map(get_baseline_prime_subtree(df_shuffle, 10)) \n",
    "# replace the first row prime NaN to [] so it can be treated universally\n",
    "df_shuffle['prime_10_random'] = [ [] if x is np.NaN else x for x in df_shuffle['prime_10_random'] ] \n",
    "df_shuffle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the overlap items in two lists (target and prime)\n",
    "# calculate the length of utterances\n",
    "def find_overlap_random(df_ms, prime_window):\n",
    "\n",
    "    prime_column = 'prime_10_random' # get the column name based on the prime_window chosed \n",
    "    len_prime_column = 'len_prime_' + str(prime_window)\n",
    "    \n",
    "    print(prime_column)\n",
    "    df_ms['overlap_count'] = 0\n",
    "    df_ms['len_target'] = 0\n",
    "    df_ms['len_prime'] = 0\n",
    "\n",
    "    for index, row in df_ms.iterrows():\n",
    "        n=0\n",
    "        # for repeated use\n",
    "#         list1 = row[prime_column].split(\"delimiter\")\n",
    "#         list2 = row['syntax_tree_current'].split(\"delimiter\")\n",
    "        list1 = row['prime_10_random']\n",
    "        list2 = row['syntax_tree_current']\n",
    "        # print(type(list1), type(list2))\n",
    "        for i in list1:\n",
    "            # print(i)\n",
    "            if i in list2: # if the item in list1 belongs to list 2, then n++\n",
    "                n+=1\n",
    "        # add columns (column manipulation: set use df.at, get use df.loc)\n",
    "        \n",
    "        df_ms.at[index,'overlap_count'] = n # set number of items that overlapped between prime and target\n",
    "        df_ms.at[index,'len_target'] = len(list2) # set length of target utterance\n",
    "        df_ms.at[index,'len_prime'] = len(list1) # set length of prime utterance\n",
    "    \n",
    "    return len_prime_column # keep the len_prime column name for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_overlap_random(df_shuffle, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visual inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed data\n",
    "df_ms = pd.read_csv(r'your file path')\n",
    "df_ms= df_ms.iloc[:,1:]\n",
    "df_ms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Distribution of SILLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ms = df_ms.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of SILLA scores\n",
    "plt.hist(df_ms[(df_ms['lla'] < 0.25)]['lla'], bins = 100)\n",
    "plt.xlim(-0.01, 0.25)\n",
    "plt.title('SILLA distribution - middle school')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of zero values of silla\n",
    "df_ms['lla'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_ms[(df_ms['lla'] != 0 )& (df_ms['lla'] < 0.25)]['lla'], bins = 100)\n",
    "plt.xlim(-0.01, 0.25)\n",
    "plt.title('SILLA distribution - middle school - nonzero only')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Distribution of Normalized LLA (nLLA)\n",
    "The distribution shape changed a bit, the scale changed, general trends look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of normalized SILLA scores\n",
    "plt.hist(df_ms['nlla'], bins = 120)\n",
    "plt.xlim(-0.2, 8)\n",
    "plt.title('nLLA distribution - middle school')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_ms[df_ms['nlla'] != 0]['nlla'], bins = 120)\n",
    "plt.xlim(-0.2, 8)\n",
    "plt.title('nLLA distribution - middle school - nonzero only')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Distribution of LLA by groups\n",
    "for more consistent figures see my ppt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1  Distribution of SILLA by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_ms.groupby('group')\n",
    "# print(list(grouped))\n",
    "\n",
    "for group in grouped:\n",
    "  # figure()\n",
    "  print(group[0])\n",
    "  group[1].lla.plot.hist(bins = 200, xlim = (-0.01, 0.2), figsize=(3,3))\n",
    "  # plot.hist(group[1].N)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2  Distribution of nLLA by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in grouped:\n",
    "  # figure()\n",
    "  print(group[0])\n",
    "  group[1].nlla.plot.hist(bins = 80, xlim = (-0.5, 6), figsize=(3,3))\n",
    "  # plot.hist(group[1].N)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 distribution of sentence length, relationship between sentence length and LLA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of sentence length\n",
    "plt.hist(df_ms['len_target'], bins = 200)\n",
    "plt.xlim(-1, 80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any patterns between sentence length and SILLA score\n",
    "x = df_ms['len_target']\n",
    "y = df_ms['lla']\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any patterns between sentence length and overlap count\n",
    "plt.scatter(df_ms['len_target'],df_ms['overlap_count'])\n",
    "m, b = np.polyfit(df_ms['len_target'], df_ms['overlap_count'], 1)\n",
    "plt.plot(df_ms['len_target'], m*df_ms['len_target'] + b,color = 'green')\n",
    "print('slop: ', m, 'intercept: ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a granular look \n",
    "plt.scatter(df_ms['len_target'],df_ms['overlap_count'])\n",
    "plt.xlim(0, 80)\n",
    "plt.ylim(-1, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Distribution of syntax subtrees\n",
    "### Among 5400 syntax rules, 18 are really polular (54% of total syntax rules), we can easily find the distortion elbow from the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of syntax subtrees\n",
    "import ast\n",
    "\n",
    "# Create dictionary\n",
    "dict_freq = {}\n",
    "special_char = 0 # track how many special characters are there (\".\" and \"\")\n",
    "# Add syntax rules (subtrees) to dictionary\n",
    "for index, row in df_ms.iterrows():\n",
    "    # Converting string to list\n",
    "    list3 = ast.literal_eval(row['syntax_tree_current']) # list3 is subtress in one utterance\n",
    "\n",
    "    # list is unhashable, convert list to tuple\n",
    "    for r in list3:   # r is each subtree\n",
    "        if tuple(r) not in dict_freq:\n",
    "            dict_freq[tuple(r)] = 0\n",
    "        dict_freq[tuple(r)] += 1\n",
    "print('special_char count: ', special_char)       \n",
    "word_freq_list = [(v,k) for k,v in dict_freq.items()]\n",
    "freq_list_sorted = sorted(word_freq_list,reverse=True)\n",
    "print(list(dict_freq.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the syntax subtree frequency dictionary \n",
    "print('unique syntax rules: ',len(dict_freq))\n",
    "print('total syntax rules freq (for all utterances):', sum(dict_freq.values()))\n",
    "listr = []\n",
    "for value in dict_freq.values():\n",
    "    listr.append(value)\n",
    "          \n",
    "print('mean syntax rules freq:', np.mean(listr))\n",
    "print('std syntax rules freq:', np.std(listr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(dict_freq)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
